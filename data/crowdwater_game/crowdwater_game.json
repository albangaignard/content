{
    "additionDate": "2019-11-14T19:35:31Z",
    "biotoolsCURIE": "biotools:CrowdWater_game",
    "biotoolsID": "CrowdWater_game",
    "confidence_flag": "high",
    "credit": [
        {
            "email": "barbara.strobl@geo.uzh.ch",
            "name": "Barbara Strobl",
            "orcidid": "https://orcid.org/0000-0001-5530-4632",
            "typeEntity": "Person"
        }
    ],
    "description": "A playful way to improve the accuracy of crowdsourced water level class data | If the game is not displayed correctly, please click here",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Validation",
                    "uri": "http://edamontology.org/operation_2428"
                }
            ]
        }
    ],
    "homepage": "https://crowdwater.ch/en/crowdwater-game/",
    "lastUpdate": "2019-11-14T19:35:31Z",
    "name": "CrowdWater game",
    "owner": "Pub2Tools",
    "publication": [
        {
            "doi": "10.1371/JOURNAL.PONE.0222579",
            "metadata": {
                "abstract": "\u00a9 2019 Strobl et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Data quality control is important for any data collection program, especially in citizen science projects, where it is more likely that errors occur due to the human factor. Ideally, data quality control in citizen science projects is also crowdsourced so that it can handle large amounts of data. Here we present the CrowdWater game as a gamified method to check crowdsourced water level class data that are submitted by citizen scientists through the CrowdWater app. The app uses a virtual staff gauge approach, which means that a digital scale is added to the first picture taken at a site and this scale is used for water level class observations at different times. In the game, participants classify water levels based on the comparison of the new picture with the picture containing the virtual staff gauge. By March 2019, 153 people had played the CrowdWater game and 841 pictures were classified. The average water level for the game votes for the classified pictures was compared to the water level class submitted through the app to determine whether the game can improve the quality of the data submitted through the app. For about 70% of the classified pictures, the water level class was the same for the CrowdWater app and game. For a quarter of the classified pictures, there was disagreement between the value submitted through the app and the average game vote. Expert judgement suggests that for three quarters of these cases, the game based average value was correct. The initial results indicate that the CrowdWater game helps to identify erroneous water level class observations from the CrowdWater app and provides a useful approach for crowdsourced data quality control. This study thus demonstrates the potential of gamified approaches for data quality control in citizen science projects.",
                "authors": [
                    {
                        "name": "Strobl B."
                    },
                    {
                        "name": "Etter S."
                    },
                    {
                        "name": "Van Meerveld I."
                    },
                    {
                        "name": "Seibert J."
                    }
                ],
                "citationCount": 3,
                "date": "2019-09-01T00:00:00Z",
                "journal": "PLoS ONE",
                "title": "The CrowdWater game: A playful way to improve the accuracy of crowdsourced water level class data"
            },
            "pmcid": "PMC6763123",
            "pmid": "31557184"
        }
    ]
}